{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 8: A construction of the Poisson process\n",
    "\n",
    "\n",
    "In this notebook we study a discrete-time process that behaves like the Poisson process at larger scales. One can also see this notebook as a <b> construction </b> of the Poisson process.\n",
    "\n",
    "Fix $T$ and $\\mu$ positive parameters and a very large integer $n$. We will see how we can naturally construct a Poisson process from a long random string of 0's and 1's.\n",
    "We take a long string of size $T\\times n$ of i.i.d. integers $(B_k)_k$ in $\\{0,1\\}$, with $\\mathbb{P}(B_k = 1) = 1-\\mathbb{P}(B_k = 0) = \\frac{\\mu}{n}$. We then record the instants at which the $1$'s appear (note that this has small proba) and check that the counting process of the $1$'s when time-rescaled by $N$ looks like a Poisson process up to time $T$.\n",
    "\n",
    "The string should look a bit like this:\n",
    "\\begin{equation}\n",
    "0000000000000000000000000 \\color{blue}{1} 00000000000000000000000000\\color{blue}{1}00000000000000000000\n",
    "\\end{equation}\n",
    "\n",
    "Denoting by $S$ the time of appearance of the first $1$, we can see that\n",
    "\\begin{align}\n",
    "    \\mathbb{P}(S/n > t) &= \\mathbb{P}(S > nt) \\\\\n",
    "    &= \\mathbb{P}(B_k = 0 \\text{ for all }k\\leq nt) \\\\\n",
    "    &= (1-\\frac{\\mu}{n})^{nt} \\\\\n",
    "    &\\to e^{-\\mu t} \\text{ as } n \\text{ goes to infinity}.\n",
    "\\end{align}\n",
    "\n",
    "This suggests that when rescaling the time by $n$, the time of appearance of $1$ should have law Exp$(\\mu)$. And by independence of the bits in the string we see that any two consecutive $1$'s will be separated by an exponential random variable with parameter $\\mu$. <b>Thus, the time-rescaled counting process of the ones should converge to a Poisson process.</b>\n",
    "\n",
    "This is what we shall see in the first part of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# length of the string\n",
    "n = 10**5 # it should go to infinity ideally but 10**5 is enough\n",
    "T = 50 \n",
    "mu = 1/5  \n",
    "# mu will ultimately be the rate of the Poisson process hidden in our construction \n",
    "\n",
    "\n",
    "# n should be seen as a quantity that will go to infinity and T as a fixed time horizon.\n",
    "# The string has total length n*T so that, once rescaled by n, the counting process will have length ~ T.\n",
    "S = np.random.choice(2, n*T, p=[1-mu/n,mu/n])# random integers from 0 (inclusive) to 2 (exclusive), size n.\n",
    "\n",
    "# There are on average n*T*mu/n = T*mu bits equal to 1. \n",
    "# Let's check that.\n",
    "print(\"T*mu = \", T*mu)\n",
    "print(\"Number of bits equal to 1 in the string S: \", np.sum(S))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_jumps = np.argwhere(S==1) # time_jumps is the vector containing the indices of S where there are ones. \n",
    "# it corresponds to the jumps of the rescaled process\n",
    "\n",
    "time_jumps = np.concatenate( time_jumps, axis=0 ) # we use this trick to have an array of reals instead of an array of array...\n",
    "\n",
    "scaled_time_jumps = time_jumps/n # we rescaled the time by n\n",
    "\n",
    "n_jumps = len(time_jumps)\n",
    "jumps = [i for i in range(n_jumps)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the plot\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 4))    \n",
    "ax.set_xlabel(\"rescaled time up to time T\")\n",
    "ax.set_ylabel(\"counting of 1's\")\n",
    "\n",
    "# Plot the theoretical pdf\n",
    "plt.step(scaled_time_jumps, jumps, label='counting process rescaled by n')\n",
    "#ax.legend(loc='best', frameon=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will refer to the <b> time-rescaled </b>graph depicted above as the counting process $(C_t)_{0\\leq t \\leq T}$.\n",
    "At that point, we see that the counting process looks very much like a Poisson process so let us check that we indeed retrieve some properties of a Poisson process of rate $\\mu$ on it.\n",
    "\n",
    "\n",
    "### 1) The law of $C_T$\n",
    "For example, we first compute the empirical law of the counting process at time $T$ and compare it to the law of a Poisson process at time $T$. Recall that if $N$ is a poisson process of rate $\\mu$ then\n",
    "\\begin{equation}\n",
    "    \\mathbb{P}(N(T) = k) = e^{-\\mu T}\\frac{(\\mu T )^k}{k!}.\n",
    "\\end{equation}\n",
    "To plot the empirical distribution of $C_T$ we will simulate many times the above construction and plot the results in an histogram that we will compare to the theoretical distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as st\n",
    "import math\n",
    "\n",
    "# input data\n",
    "N_sim = 10**3 # number of simulations\n",
    "n = 10**4 \n",
    "T = 50 \n",
    "mu = 1/5 \n",
    "\n",
    "C_T_array = np.zeros(N_sim)\n",
    "\n",
    "for i in range(N_sim):\n",
    "    S = np.random.choice(2, n*T, p=[1-mu/n,mu/n]) # create a new random string every time\n",
    "    C_T_array[i] = np.sum(S)\n",
    "    # C_T corresponds simply to the total number of ones in the string \n",
    "    # since this latter quantity is the number of jumps \n",
    "    # in the process C_t and thus its value at the final time t=T.\n",
    "\n",
    "# Plot the empirical histogram and the theoretical pdf for T to compare\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 4))    \n",
    "ax.set_xlabel(\"histogram bin\")\n",
    "ax.set_ylabel(\"distribution of C_T and N_T\")\n",
    "\n",
    "# Compute and plot the histogram\n",
    "weights = np.ones_like(C_T_array) / len(C_T_array) # this vector is used to normalize this histogram \n",
    "# so that the bars sum up to 1\n",
    "ti, bins, pr = ax.hist(C_T_array, 100, weights = weights, label = 'empirical distribution')\n",
    "\n",
    "# Specify the theoretical pdf in a good range of values\n",
    "a,b = math.ceil(bins[0]),math.ceil(bins[-1])\n",
    "f_T = np.zeros(b-a)\n",
    "for k in range(a,b):\n",
    "    f_T[k-a] = np.exp(-mu*T)*(mu*T)**k/math.factorial(k) # f is the (discrete) law of N_T\n",
    "    \n",
    "# Plot the theoretical pdf\n",
    "ax.plot(range(a,b),f_T,'--', label='Theoretical pdf')\n",
    "ax.legend(loc='best', frameon=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the graphs look alike even though there is some apparent variability in the results. Since $N$ and $n$ should both be very large to have interesting results you can check that decreasing one of these parameters leads to less accuracy in the prediction.\n",
    "\n",
    "### 2) The distribution of the instant of the first jump in $(C_t)_{0\\leq t \\leq T}$\n",
    "Another thing that we can look at is the time of the first jump, we should recover that it is approximativey given by an exponential distribution with parameter $\\mu$. The larger $n$ and $N$ are, the better the approximation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as st\n",
    "import math\n",
    "\n",
    "# input data\n",
    "N_sim = 10**3 # number of simulations\n",
    "n = 10**4 \n",
    "T = 70 \n",
    "mu = 1/5 \n",
    "\n",
    "C_T_array = np.zeros(N_sim)\n",
    "\n",
    "for i in range(N_sim):\n",
    "    S = np.random.choice(2, n*T, p=[1-mu/n,mu/n]) # create a new random string every time\n",
    "    time_jumps = np.argwhere(S==1)\n",
    "    C_T_array[i] = time_jumps[0]/n # take the normalized time of the first jump \n",
    "    \n",
    "    # It is possible though with very small probability that S contains no 1. In this case, the cell\n",
    "    # will return an exception since time_jumps[0] will try to access the first element of an empty array.\n",
    "    # If this is the case, you can just rerun the cell which should be fine since this has very small probability.\n",
    "    # Otherwise, you could modify the code to take into account these events into the description of the empirical distribution\n",
    "    # of the first jump.\n",
    "\n",
    "    \n",
    "# Plot the empirical histogram and the theoretical pdf for T to compare\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 4))    \n",
    "ax.set_xlabel(\"histogram bin\")\n",
    "ax.set_ylabel(\"distribution of the time of the first jump in C_t\")\n",
    "\n",
    "# Definite the theoretical pdf\n",
    "def pdf(x):\n",
    "    return mu*np.exp(-mu*x)\n",
    "# Compute and plot the histogram\n",
    "\n",
    "ti, bins, pr = ax.hist(C_T_array, 100, density = True, label = 'empirical distribution',alpha = 0.8)\n",
    "   \n",
    "# Plot the theoretical pdf\n",
    "x_axis = np.arange(0, bins[-1], 0.2)\n",
    "ax.plot(x_axis, [pdf(x) for x in x_axis], '--', label='Exp(mu) pdf')\n",
    "ax.legend(loc='best', frameon=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) The distribution of the instant of later jumps in $(C_t)_{0\\leq t \\leq T}$\n",
    "\n",
    "By modifying slightly the code above, can you plot the empirical law of the instant of the $10$-th jump? What should it be theoretically and is it what you observe? \n",
    "\n",
    "Note that it is possible that you don't oberserve $10$ $1$'s in the string $S$ and therefore that the $10$-th jump does not exist. You may take $T$ large enough to have an overwhelming probability to see $10$ jumps or you can try to observe anterior jumps like the $4$ or $5$ jumps for example and then one does not need $T$ to be too large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as st\n",
    "import math\n",
    "\n",
    "# input data\n",
    "N_sim = 10**3 # number of simulations\n",
    "n = 10**4 \n",
    "T = 200 \n",
    "mu = 1/5 \n",
    "n_jump = 10 # observe the 10-th jump\n",
    "\n",
    "C_T_array = np.zeros(N_sim)\n",
    "\n",
    "for i in range(N_sim):\n",
    "    S = np.random.choice(2, n*T, p=[1-mu/n,mu/n]) # create a new random string every time\n",
    "    time_jumps = np.argwhere(S==1)\n",
    "    C_T_array[i] = time_jumps[n_jump-1]/n # take the normalized time of the n_jump-th jump\n",
    "    \n",
    "\n",
    "    \n",
    "# Plot the empirical histogram and the theoretical pdf \n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 4))    \n",
    "ax.set_xlabel(\"histogram bin\")\n",
    "ax.set_ylabel(\"distribution of the time of the first jump in C_t\")\n",
    "\n",
    "# Definite the theoretical pdf\n",
    "# The k-th jumps has law Gamma(k,mu)\n",
    "def pdf(x):\n",
    "    return mu*np.exp(-mu*x)*((mu*x)**(n_jump-1))/math.factorial(n_jump-1)\n",
    "\n",
    "# Compute and plot the histogram\n",
    "ti, bins, pr = ax.hist(C_T_array, 100, density = True, label = 'empirical distribution',alpha = 0.8)\n",
    "   \n",
    "# Plot the theoretical pdf\n",
    "x_axis = np.arange(0, bins[-1], 0.2)\n",
    "ax.plot(x_axis, [pdf(x) for x in x_axis], '--', label='Exp(mu) pdf')\n",
    "ax.legend(loc='best', frameon=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 8 - Problem 6\n",
    "## Non-homogeneous Poisson Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
